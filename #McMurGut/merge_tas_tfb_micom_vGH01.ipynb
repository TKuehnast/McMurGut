{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36809e39-3d37-4b58-9b68-dae235b90ad1",
   "metadata": {},
   "source": [
    "# Script Merge tas tfb micom\n",
    "Version GitHub 01\n",
    "\n",
    "Transformation of heavily modified taxonomy file and table.from_biom file  \n",
    "into python-based MICOM-compatible 1-dimensional id/taxonomy/sample_id/abundance csv file  \n",
    "\n",
    "########################################################  \n",
    "By Torben Kuehnast, torben.kuehnast@gmail.com, 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ddf93-3685-4b91-b1f0-46d589248d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954908c-5fee-47fc-b2f2-f632e2fdf6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########INPUT FIELD#############\n",
    "# Before you start:\n",
    "\n",
    "### INPUT:\n",
    "# Insert file name for XXX_table.from_biom.csv - aside of XXX, the file name has to be PRECISELY like that!\n",
    "filepath_tfb = '/home/project_table-from-biom.csv'\n",
    "# --> it has to contain:\n",
    "# ASV ------- sample1  --- sample2  --- ...\n",
    "# <ident> --- <number> --- <number> --- ...\n",
    "# <ident> --- <number> --- <number> --- ...\n",
    "# So first column with ASV identifiers\n",
    "# Second column containing the first sample_id in the header and the abundance-number\n",
    "# corresponding to the ASV identifier in the same row\n",
    "\n",
    "### INPUT:\n",
    "# Insert file name for XXX_taxa_abund_sample.csv - aside of XXX, the file name has to be PRECISELY like that!\n",
    "filepath_tas = '/home/project_taxa_abund_sample.csv'\n",
    "# --> it has to contain:\n",
    "# id, kingdom, phylum, class, order, family, genus, species\n",
    "# Make sure all fields filled up!\n",
    "# Make sure id (a random unique identifier of the respective row) was prepared beforehand.\n",
    "# ALERT: the order and count of the rows must be the SAME for BOTH files.\n",
    "# ALERT: If not, you will mix up the wrong abundances to the wrong taxa, or create fatal errors.\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('## DATA OVERVIEW ##')\n",
    "print('----------------------')\n",
    "print('filepath_tfb is:', filepath_tfb)\n",
    "print('filepath_tas is:', filepath_tas)\n",
    "print('-----------')\n",
    "# extracting project name from XXX_...\n",
    "project_tas = os.path.basename(filepath_tas).split('_taxa_abund_sample.csv', 1)[0]\n",
    "print('project_tas is:', project_tas)\n",
    "print('-----------')\n",
    "data_tfb = pd.read_csv(filepath_tfb, sep=\";\")\n",
    "print('data_tfb is:', data_tfb.head(4))\n",
    "print('-----------')\n",
    "data_tas = pd.read_csv(filepath_tas, sep=\";\")\n",
    "print('data_tas is:', data_tas.head(4))\n",
    "print('-----------')\n",
    "# showing sample lists\n",
    "print('samples in the table from biome (please verify):', data_tfb.columns)\n",
    "print('-----------')\n",
    "\n",
    "# in table from biom we have 113 columns. \n",
    "column_count_tfb = data_tfb.shape[1]\n",
    "print('columns counted in table from biome:', column_count_tfb)\n",
    "\n",
    "sample_count_tfb = column_count_tfb\n",
    "print('column in tfb minus 1 = samples counted in table from biome:', sample_count_tfb)\n",
    "print('-----------')\n",
    "\n",
    "print(\"Total count of samples found in taxa.from.biom:\", sample_count_tfb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample that the loop is currently working on. Giving it 0 for start.\n",
    "current_working_sample = 0\n",
    "\n",
    "# We create the foundation for the final micom file, containing all 10 columns, of all samples and taxa\n",
    "# Initially, just the column headers\n",
    "final_micom_tas = pd.DataFrame(columns=['id', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species', 'sample_id', 'abundance'])\n",
    "final_micom_tas\n",
    "# With each sample in the for loob, we will be adding a bunch of rows, until all samples are integrated.\n",
    "# Then it is ready for micom.\n",
    "\n",
    "\n",
    "# Modify column headers, to make sure writing is correct for micom\n",
    "data_tas_col = data_tas\n",
    "data_tas_col.columns = ['id', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']\n",
    "data_tas_col\n",
    "# data_tas_col serves as taxa pattern, not changed during program\n",
    "\n",
    "\n",
    "# Going through all the samples listed in the table.from_biom.csv\n",
    "# Use range() to transform sample_count_tfv into usable int numbers\n",
    "for current_working_sample in range(1, sample_count_tfb):\n",
    "    # which sample are we in      (ASV - Sample1 - Sample2 - Sample3 ....)?\n",
    "    # Number of sample_count_tfb:   0       1         2         3  \n",
    "    # Range starts at _1_! This way we leave out ASV column.\n",
    "    print('Sample number:', current_working_sample)\n",
    "    \n",
    "    # What is column header-name at current position?\n",
    "    # find the column name of the current_work_sample in the data_tfb and show it\n",
    "    sample_id = [data_tfb.columns[current_working_sample]]\n",
    "    print('Sample_id: ', sample_id)\n",
    "    \n",
    "    #Look through data_tfb, containing:\n",
    "    #print(\"Origin of data_tfb: \", filepath_tfb)\n",
    "    # for a COLUMN whose header is called:\n",
    "    #print(\"Column with THIS header we look for: \", sample_id)\n",
    "    \n",
    "    sample_data = data_tfb[[data_tfb.columns[current_working_sample]]]\n",
    "    #print(\"Show me current column, stored in sample_data:\", sample_data)\n",
    "           \n",
    "    # From our current column, or respectively, the whole data_tfb: how many rows does it even have?\n",
    "    # Count rows of our table from biom file and store the count in tfb_column_count\n",
    "    tfb_column_count = data_tfb.shape[0]\n",
    "    #print('ROWS in the current column/file:', tfb_column_count)\n",
    "    \n",
    "    \n",
    "    # Storing the column from \"sample_data\" in abundance_column as DataFrame with abundance header\n",
    "    #OLD(doesnt work): abundance_column = pd.DataFrame(sample_data, columns=[\"abundance\"])\n",
    "    #NEW:\n",
    "    abundance_column = sample_data\n",
    "    #set column header to abundance\n",
    "    abundance_column.columns = ['abundance']\n",
    "    #print(\"abundance_column: \", abundance_column)\n",
    "    \n",
    "    \n",
    "    #debugging\n",
    "    if tfb_column_count == 0:\n",
    "        print(\"Error: You have no data in your abundance table of sample: \", sample_id)\n",
    "    #debugging\n",
    "    if tfb_column_count == 1:\n",
    "        print(\"Alert: You only have 1 column in your dataset, usually ASV identifiers:\", sample_id)\n",
    "    #debugging\n",
    "    if tfb_column_count == 2:\n",
    "        print(\"Alert: You have just one sample. Is it intended? -->\", sample_id)\n",
    "        \n",
    "    # The initial sample_id column, which is incremented x times (x = tfb_column_count)\n",
    "    incre_sample_id = pd.DataFrame(sample_id, columns=[\"sample_id\"])\n",
    "    #print(\"incre_sample_id\", incre_sample_id)\n",
    "\n",
    "    # The 1x_sample_id column, which is added to incre_sample_id each loop\n",
    "    one_added_sample_id = pd.DataFrame(sample_id, columns=[\"sample_id\"])\n",
    "    #print(\"one_added_sample_id:\", one_added_sample_id)\n",
    "\n",
    "    # So, initially, incre_sample_id has only 1 sample-id row\n",
    "    # This is now incremented with each loop for that many times as we have rows in the abundance files\n",
    "\n",
    "    x = 0\n",
    "    print(\"Initial tfb_column_count:\", tfb_column_count)\n",
    "    for x in range(1, tfb_column_count):\n",
    "        #print(\"x:\", x)\n",
    "\n",
    "        incre_sample_id = pd.concat([incre_sample_id, one_added_sample_id], ignore_index=True)\n",
    "        #print(\"New incre_sample_id: \", incre_sample_id)\n",
    "        #print(\"---------------- loop ended ---------------\")\n",
    "    \n",
    "    # Combine the freshly created incre_sample_id (sample_id column)\n",
    "    # with the abundance_column (abundance values column)\n",
    "    samp_id_abund_column = pd.concat([incre_sample_id, abundance_column], axis=1)\n",
    "    #print(\"samp_id_abund_column: \", samp_id_abund_column)\n",
    "    \n",
    "    #Now combine samp_id_abund_column (2 columns: abundance and sample_id)\n",
    "    #..with data_tas_col (8 columns: id and taxas)\n",
    "    samp_id_abund_column_merge = pd.concat([data_tas_col, samp_id_abund_column], axis=1)\n",
    "    print(\"Taxa/abundance/id/sample_id of\", sample_id, \":\", samp_id_abund_column_merge)\n",
    "    #..creating samp_id_abund_column_merge (10 columns: id, taxa, sample_id, abundance)\n",
    "    #.. of ONE sample (the one currently in the foor loop)\n",
    "\n",
    "    # Now, this has to be appended to the final_micom_tas:  \n",
    "    final_micom_tas = pd.concat([final_micom_tas, samp_id_abund_column_merge], ignore_index=True)\n",
    "    print(\"Growing final_micom_tas dataframe:\", final_micom_tas)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    print('--------------------------------')\n",
    "    \n",
    "    \n",
    "print('-- Sample loop ended --------------------------------')\n",
    "print('Transformed final_micom_tas should be created:', final_micom_tas)\n",
    "\n",
    "df = pd.DataFrame(final_micom_tas)\n",
    "df.to_csv(project_tas+'_final_micom_tas.csv', index=False, header=True)\n",
    "\n",
    "print(\"---- Created: ----\")\n",
    "print(\"\")\n",
    "print(os.path.abspath(\"\")+\"/\"+project_tas+'_final_micom_tas.csv')\n",
    "print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b7a040-e1ed-4d1a-b142-b1ca02983ec2",
   "metadata": {},
   "source": [
    "# Script Merge tas tfb micom\n",
    "Finished!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
