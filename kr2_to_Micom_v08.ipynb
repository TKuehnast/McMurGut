{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae432e82-4a7a-4d7b-a961-a2441d5ff97e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "## This script takes output from Kraken2 or Bracken which was previously transformed into\n",
    "## mpa-like datasheets via the KrakenTools-script kreport2mpa.py.\n",
    "\n",
    "## INPUT\n",
    "# You copy all your Kraken2/Bracken-output into a new directory on the cluster\n",
    "# You add the full path of this directory to the input section (directory_path)\n",
    "# You look at the name of our Kraken2/Bracken-output an\n",
    "# Example: the files are called:\n",
    "# Example: SRR7658581_report_bracken_species_taxinfo.out\n",
    "# Example: SRR7658590_report_bracken_species_taxinfo.out ...\n",
    "# Example: \"SRR7658590\" is the variable part, defining the sample's name\n",
    "# Example: \"_report_bracken_species_taxinfo.out\" is the conserved part which stays the same in all files\n",
    "# Now in the input section, you add the conserved part in \"active_input\".\n",
    "\n",
    "# PROCEDURE:\n",
    "# The script screens through directory_path for files that have the ending\n",
    "# that you define in the input section (active_input) in the directory_path\n",
    "\n",
    "## The files will ONLY contain species-taxonomy\n",
    "## All genus and higher taxonomy (some reads are this level only!) will be discarded\n",
    "##  If you need these, please let me know and I will try to modify it\n",
    "## An id is created which is made of species name and an incrementing number\n",
    "## The script will also create Namco/MicrobiomeExplorer-style data\n",
    "## They id is replaced by the species-name\n",
    "## The sample-id is a column header, the sample's abundance is now in each column\n",
    "## It will also create a merged version of taxonomy and abundance\n",
    "\n",
    "# The output will be stored in folder directory_path/01_trafo (you can change that)\n",
    "\n",
    "# The output contains:\n",
    "# - MICOM-style individual samples:\n",
    "#        -> <variable samples name>_bra_mpa_trafo.csv\n",
    "\n",
    "# - MICOM-style SUMMARY of all samples:\n",
    "#        -> Bra_mpa_trafo_summary_micom.csv\n",
    "\n",
    "# - NAMCO-style data-files:\n",
    "#        -> Bra_mpa_trafo_summary_taxonomy.csv     / like a Qiime2 taxonomy.tsv\n",
    "#        -> Bra_mpa_trafo_summary_featuretable.csv / like a Qiime2 feature table biom file\n",
    "\n",
    "\n",
    "# - A merged version of feature table and taxonomy file, which may be used for other analyses\n",
    "#        -> TKWGS_k2_mpa_trafo_summary_merge_tax_ab.csv (both merged)\n",
    "\n",
    "###################################################\n",
    "## Torben Kuehnast, 2024, torben.kuehnast@gmail.com\n",
    "###################################################\n",
    "# Versions\n",
    "# v06: now includes instantly compatible output for Namco.\n",
    "# v07: updated input to be more general and less specific\n",
    "# v08: version for github\n",
    "###################################################\n",
    "\n",
    "\n",
    "\n",
    "############## INPUT HERE ##############################\n",
    "############## INPUT HERE ##############################\n",
    "############## INPUT HERE ##############################\n",
    "\n",
    "# Global directory: this one is screened for input files!\n",
    "directory_path = \"/home/\"\n",
    "# Conserved part of your samples file names (same in all samples)\n",
    "# This will be looked for automatically by the program.\n",
    "active_input = \"_report_bracken_species_taxinfo.out\"\n",
    "\n",
    "\n",
    "# Change, if you want a different output path. \n",
    "# Default is creating a new folder called 01_trafo and storing there.\n",
    "output_path = os.path.join(directory_path, \"01_trafo\")\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Change if you want different OUTPUT names.\n",
    "inter_filename = \"_bra_mpa_trafo.csv\"\n",
    "micom_summary = \"Bra_mpa_trafo_summary_micom.csv\"\n",
    "output_merged = os.path.join(output_path, \"Bra_mpa_trafo_summary_merge_tax_ab.csv\")\n",
    "output_taxonomy = os.path.join(output_path, \"Bra_mpa_trafo_summary_taxonomy.csv\")\n",
    "output_abundance = os.path.join(output_path, \"Bra_mpa_trafo_summary_featuretable.csv\")\n",
    "\n",
    "###################Input END##########################\n",
    "###################Input END##########################\n",
    "###################Input END##########################\n",
    "\n",
    "\n",
    "################### Start program ####################\n",
    "################### Start program ####################\n",
    "################### Start program ####################\n",
    "\n",
    "print(\"#active_input:\", active_input)\n",
    "print(\"#directory_path:\", directory_path)\n",
    "print(\"#output_path:\", output_path)\n",
    "print(\"#inter_filename:\", inter_filename)\n",
    "print(\"#micom_summary:\", micom_summary)\n",
    "print(\"output_merged:\", output_merged)\n",
    "print(\"output_taxonomy:\", output_taxonomy)\n",
    "print(\"output_abundance:\", output_abundance)\n",
    "print(\":\", )\n",
    "\n",
    "# Counter for unique \"id\" generation.\n",
    "id_counter = 0\n",
    "\n",
    "print(\"Starting to sort -metaphlan-like to micom-style.\")\n",
    "for filename in os.listdir(directory_path):\n",
    "    # The whole folder from input will be looked for the ending you specified in active_input\n",
    "    if filename.endswith(active_input):\n",
    "        sample_name = filename.split(active_input)[0]\n",
    "        print(\"sample_name:\", sample_name)\n",
    "        target_filename = os.path.join(output_path, f\"{sample_name}{inter_filename}\")\n",
    "\n",
    "        print(\"-----------------\")\n",
    "        print(\"Analysing the following file:\")\n",
    "        print(\"filename:\", filename)\n",
    "        \n",
    "        # saving the summary of all samples in here:\n",
    "        summary_file = os.path.join(output_path, f\"{micom_summary}\")\n",
    "        print(\"summary_file\", summary_file)\n",
    "\n",
    "\n",
    "        # Ziel-CSV-Datei erstellen\n",
    "        header = [\"id\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\", \"sample_id\", \"abundance\"]\n",
    "        print(\"Creating new sample file:\", target_filename)\n",
    "        with open(target_filename, \"w\", newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=';')\n",
    "            csv_writer.writerow(header)\n",
    "\n",
    "\n",
    "        if not os.path.exists(summary_file):\n",
    "            print(\"Summary file doesnt exist. Creating new one:\", summary_file)\n",
    "            with open(summary_file, \"w\", newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=';')\n",
    "                csv_writer.writerow(header)\n",
    "\n",
    "        source_filepath = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(source_filepath, sep='\\t', header=None)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            id_counter += 1\n",
    "            kingdom = phylum = _class = _order = family = genus = species = sample_id = \"\"\n",
    "            abundance = 0.0\n",
    "            \n",
    "            first_col = row[0]\n",
    "            patterns = [\"s__\", \"g__\", \"f__\", \"o__\", \"c__\", \"p__\", \"k__\", \"d__\"]  # 'd__' hinzugefügt\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                if pattern in first_col:\n",
    "                    parts = first_col.split(\"|\")\n",
    "                    for part in parts:\n",
    "                        if part.startswith((\"k__\", \"d__\")):  # 'd__' hinzugefügt\n",
    "                            kingdom = part[3:]\n",
    "                        elif part.startswith(\"p__\"):\n",
    "                            phylum = part[3:]\n",
    "                        elif part.startswith(\"c__\"):\n",
    "                            _class = part[3:]\n",
    "                        elif part.startswith(\"o__\"):\n",
    "                            _order = part[3:]\n",
    "                        elif part.startswith(\"f__\"):\n",
    "                            family = part[3:]\n",
    "                        elif part.startswith(\"g__\"):\n",
    "                            genus = part[3:]\n",
    "                        elif part.startswith(\"s__\"):\n",
    "                            species = part[3:]\n",
    "                    \n",
    "                    abundance = float(row[1])\n",
    "                    \n",
    "                    if species:\n",
    "                        id_combined = species+\"_\"+str(id_counter)\n",
    "                        with open(target_filename, \"a\", newline='') as f:\n",
    "                            csv_writer = csv.writer(f, delimiter=';')\n",
    "                            csv_writer.writerow([id_combined, kingdom, phylum, _class, _order, family, genus, species, sample_name, abundance])\n",
    "\n",
    "                        with open(summary_file, \"a\", newline='') as f:\n",
    "                            csv_writer = csv.writer(f, delimiter=';')\n",
    "                            csv_writer.writerow([id_combined, kingdom, phylum, _class, _order, family, genus, species, sample_name, abundance])\n",
    "                    \n",
    "                    break\n",
    "        print(\"Wrote\", target_filename)\n",
    "        print(\"Updated\", summary_file)\n",
    "        print(\"-------------\")\n",
    "print(f\"Finished creation of micom-like files.\")\n",
    "print(\"--------------------------\")\n",
    "print(\"NEXT STEP: Modifying micom-style to fit Namco/MicrobiomExplorer-style:\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "############################################################################################\n",
    "### Modifying micom-style to fit Namco/MicrobiomExplorer-style:\n",
    "\n",
    "           \n",
    "input_file = summary_file\n",
    "print(\"Working on:\", input_file)\n",
    "# 1. Laden der CSV-Datei mit dem korrekten Trennzeichen\n",
    "df = pd.read_csv(input_file, delimiter=';')\n",
    "\n",
    "# 2. Initialisieren eines leeren DataFrame zur Speicherung der umstrukturierten Daten\n",
    "columns = ['id', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']\n",
    "restructured_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# 3. Durchlaufen jeder Zeile im originalen DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    species = row['species']\n",
    "    sample_id = row['sample_id']\n",
    "    abundance = int(row['abundance'])  # Konvertieren in Integer\n",
    "    \n",
    "    # 4. Überprüfen, ob die Spezies bereits im umstrukturierten DataFrame ist\n",
    "    species_row = restructured_df[restructured_df['id'] == species]\n",
    "    \n",
    "    if species_row.empty:\n",
    "        # 4.1 Fügen Sie eine neue Zeile für diese Spezies hinzu\n",
    "        new_row = pd.DataFrame({col: [row[col]] if col != 'id' else [species] for col in columns})\n",
    "        new_row[sample_id] = abundance\n",
    "        restructured_df = pd.concat([restructured_df, new_row], ignore_index=True)\n",
    "    else:\n",
    "        # 4.2 Aktualisieren der vorhandenen Zeile mit dem neuen Abundanzwert\n",
    "        restructured_df.loc[restructured_df['id'] == species, sample_id] = abundance\n",
    "print(\"Finished all 1D-sample/abundance to 2D-sample/abundance\")\n",
    "\n",
    "# 5. Füllen Sie alle NaN-Werte mit 0 und konvertieren Sie die Zahlen in Integer\n",
    "restructured_df.fillna(0, inplace=True)\n",
    "for col in restructured_df.columns[8:]:  # Wir starten bei der ersten 'sample_id'-Spalte\n",
    "    restructured_df[col] = restructured_df[col].astype(int)\n",
    "print(\"Changed empty fields to value zero.\")\n",
    "\n",
    "# 6. Speichern des umstrukturierten DataFrames als neue CSV-Datei\n",
    "restructured_df.to_csv(output_merged, index=False, sep=';')\n",
    "print(\"Creating\", output_merged)\n",
    "\n",
    "# 7. Erstellen der output_taxonomy CSV-Datei\n",
    "taxonomy_df = restructured_df[['id', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']]\n",
    "\n",
    "# debug capitalizing for Namco:\n",
    "taxonomy_df = taxonomy_df.rename(columns={\n",
    "    'kingdom': 'Kingdom',\n",
    "    'phylum': 'Phylum',\n",
    "    'class': 'Class',\n",
    "    'order': 'Order',\n",
    "    'family': 'Family',\n",
    "    'genus': 'Genus',\n",
    "    'species': 'Species'\n",
    "})\n",
    "\n",
    "taxonomy_df.to_csv(output_taxonomy, index=False, sep='\\t')\n",
    "print(\"Created\", output_taxonomy)\n",
    "\n",
    "# 8. Erstellen der output_abundance CSV-Datei\n",
    "abundance_df = restructured_df.drop(columns=['kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species'])\n",
    "abundance_df.to_csv(output_abundance, index=False, sep='\\t')\n",
    "print(\"Created\", output_abundance)\n",
    "print(\"-------------------------\")\n",
    "print(\"----->>>  Finished all. TK.\")\n",
    "print(\"-------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEW_qiime2-2023.5",
   "language": "python",
   "name": "new_qiime2-2023.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
